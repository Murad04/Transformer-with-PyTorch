{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO89Z5qcVrwmu2E9aQy/9gL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "id": "GgylTY4hIYee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "id": "7Kwg_un5LYnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer"
      ],
      "metadata": {
        "id": "oNwm7XH-Lkfa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable,List\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from timeit import default_timer as timer\n",
        "from torch.nn import Transformer\n",
        "from torch import Tensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "Doj9nl7aL62A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as NN\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "spacy.prefer_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yuBYtClMU3J",
        "outputId": "d0df60b3-5142-48a1-b105-1ebbf4cea49e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic=True\n",
        "torch.backends.cudnn.benchmark=True"
      ],
      "metadata": {
        "id": "ScSKV6FLMeWW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE='en'\n",
        "TGT_LANGUAGE='fr'"
      ],
      "metadata": {
        "id": "_3F8o5CaMsDN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform={}\n",
        "vocab_transform={}\n",
        "token_transform[SRC_LANGUAGE]=get_tokenizer('spacy',language='en_core_web_sm')\n",
        "token_transform[TGT_LANGUAGE]=get_tokenizer('spacy',language='fr_core_news_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqSlWMbMMxiM",
        "outputId": "9318309d-841f-46fe-9cbe-70aca42ba9c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv=pd.read_csv(\n",
        "    'eng_-french.csv',\n",
        "    usecols=['English words/sentences', 'French words/sentences']\n",
        ")\n",
        "csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B7KUQ3byNrIS",
        "outputId": "d195d0cb-96ca-411d-f50d-3a6bbc31a43c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                     Hi.                 Salut!\n",
              "1                    Run!                Cours !\n",
              "2                    Run!               Courez !\n",
              "3                    Who?                  Qui ?\n",
              "4                    Wow!             Ça alors !"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-193a2501-9b66-40d0-afb0-f9a25fb5e3fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-193a2501-9b66-40d0-afb0-f9a25fb5e3fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-193a2501-9b66-40d0-afb0-f9a25fb5e3fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-193a2501-9b66-40d0-afb0-f9a25fb5e3fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1573688a-21f5-4852-8d7b-3d6c153fdc82\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1573688a-21f5-4852-8d7b-3d6c153fdc82')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1573688a-21f5-4852-8d7b-3d6c153fdc82 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "csv"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv,test_csv=train_test_split(csv,test_size=0.1)"
      ],
      "metadata": {
        "id": "tKy4nPZVOXoU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkafcOEubTjS",
        "outputId": "02fb916b-e3f7-4b9b-afc4-3740830d6422"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158058"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq_NbttgdOld",
        "outputId": "97505945-20e8-4a75-c32f-2d9679bbdcd2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17563"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "1MXTAyo9bgJm",
        "outputId": "746c6185-26f1-430f-db0d-c8d380d5329a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               English words/sentences  \\\n",
              "158383  They kept him waiting outside for a long time.   \n",
              "146722       How much money did you spend on your car?   \n",
              "120085              I heard it from a reliable source.   \n",
              "152460     My parents met each other in the mountains.   \n",
              "63136                        My teacher drove me home.   \n",
              "...                                                ...   \n",
              "119879              I don't want to lose my boyfriend.   \n",
              "103694                 I will never forget seeing you.   \n",
              "131932            Who told you that we should do that?   \n",
              "146867       I decided to go out and explore the town.   \n",
              "121958              The mechanic assembled the engine.   \n",
              "\n",
              "                                   French words/sentences  \n",
              "158383                   Ils le firent poireauter dehors.  \n",
              "146722  Combien d'argent avez-vous dépensé pour votre ...  \n",
              "120085               Je l'ai entendu d'une source fiable.  \n",
              "152460  Mes parents se sont rencontrés dans les montag...  \n",
              "63136              Mon professeur m'a reconduit chez moi.  \n",
              "...                                                   ...  \n",
              "119879               Je ne veux pas perdre mon petit ami.  \n",
              "103694                  Je n'oublierai jamais t'avoir vu.  \n",
              "131932      Qui vous a dit que nous devrions faire cela ?  \n",
              "146867      J’ai décidé de sortir et d’explorer la ville.  \n",
              "121958                  Le mécanicien assembla le moteur.  \n",
              "\n",
              "[158058 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a129ce8-1eb5-46af-94bc-1be0062ad6b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>158383</th>\n",
              "      <td>They kept him waiting outside for a long time.</td>\n",
              "      <td>Ils le firent poireauter dehors.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146722</th>\n",
              "      <td>How much money did you spend on your car?</td>\n",
              "      <td>Combien d'argent avez-vous dépensé pour votre ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120085</th>\n",
              "      <td>I heard it from a reliable source.</td>\n",
              "      <td>Je l'ai entendu d'une source fiable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152460</th>\n",
              "      <td>My parents met each other in the mountains.</td>\n",
              "      <td>Mes parents se sont rencontrés dans les montag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63136</th>\n",
              "      <td>My teacher drove me home.</td>\n",
              "      <td>Mon professeur m'a reconduit chez moi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119879</th>\n",
              "      <td>I don't want to lose my boyfriend.</td>\n",
              "      <td>Je ne veux pas perdre mon petit ami.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103694</th>\n",
              "      <td>I will never forget seeing you.</td>\n",
              "      <td>Je n'oublierai jamais t'avoir vu.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>Who told you that we should do that?</td>\n",
              "      <td>Qui vous a dit que nous devrions faire cela ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146867</th>\n",
              "      <td>I decided to go out and explore the town.</td>\n",
              "      <td>J’ai décidé de sortir et d’explorer la ville.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>The mechanic assembled the engine.</td>\n",
              "      <td>Le mécanicien assembla le moteur.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>158058 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a129ce8-1eb5-46af-94bc-1be0062ad6b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a129ce8-1eb5-46af-94bc-1be0062ad6b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a129ce8-1eb5-46af-94bc-1be0062ad6b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5766ee2d-0040-4e0f-a309-f571643b2395\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5766ee2d-0040-4e0f-a309-f571643b2395')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5766ee2d-0040-4e0f-a309-f571643b2395 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_186cf58a-6853-4d08-956e-1ac06741c9b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_csv')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_186cf58a-6853-4d08-956e-1ac06741c9b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_csv');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_csv"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "  def __init__(self,csv):\n",
        "    self.csv=csv\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.csv)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return(\n",
        "        self.csv['English words/sentences'].iloc[idx],\n",
        "        self.csv['French words/sentences'].iloc[idx]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "0ta9IZgWOfQD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=TranslationDataset(train_csv)\n",
        "valid_dataset=TranslationDataset(test_csv)\n",
        "\n",
        "iterator=iter(train_dataset)\n",
        "print(next(iterator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQcra5FOQp1M",
        "outputId": "8307ad5b-8c3f-4bff-9b20-bbf92d941446"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('They kept him waiting outside for a long time.', 'Ils le firent poireauter dehors.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter:Iterable,language:str)->List[str]:\n",
        "  language_index={SRC_LANGUAGE:0,TGT_LANGUAGE:1}\n",
        "\n",
        "  for data_sample in data_iter:\n",
        "    yield token_transform[language](data_sample[language_index[language]])"
      ],
      "metadata": {
        "id": "L2FsmP73Q5BI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX,PAD_IDX,BOS_IDX,EOS_IDX=0,1,2,3\n",
        "special_symbols=['<unk>','<pad>','<bos>','<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
        "  vocab_transform[ln]=build_vocab_from_iterator(\n",
        "      yield_tokens(train_dataset,ln),\n",
        "      min_freq=1,\n",
        "      specials=special_symbols,\n",
        "      special_first=True,\n",
        "  )\n",
        "\n",
        "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "rYdX6O6fRX8z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_transform(*transforms):\n",
        "  def func(txt_input):\n",
        "    for transform in transforms:\n",
        "      txt_input=transform(txt_input)\n",
        "    return txt_input\n",
        "  return func\n",
        "\n",
        "def tensor_transform(token_ids:List[int]):\n",
        "  return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                    torch.tensor(token_ids),\n",
        "                    torch.tensor([EOS_IDX])))\n",
        "\n",
        "text_transform={}\n",
        "for ln in [SRC_LANGUAGE,TGT_LANGUAGE]:\n",
        "  text_transform[ln]=sequential_transform(token_transform[ln],\n",
        "                                          vocab_transform[ln],\n",
        "                                          tensor_transform)\n",
        "\n",
        "def collate_fn(batch):\n",
        "  src_batch,tgt_batch=[],[]\n",
        "  for src_sample,tgt_sample in batch:\n",
        "    src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "    tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "  tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "  return src_batch, tgt_batch\n"
      ],
      "metadata": {
        "id": "1bnC9wHFR-N3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 192\n",
        "NHEAD = 6\n",
        "FFN_HID_DIM = 192\n",
        "BATCH_SIZE = 192\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "DEVICE = 'cuda'\n",
        "NUM_EPOCHS = 4"
      ],
      "metadata": {
        "id": "hfFMH3hHTbzy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "  mask=(torch.triu(torch.ones((sz,sz),device=DEVICE))==1).transpose(0,1)\n",
        "  mask=mask.float().masked_fill(mask==0,float('-inf')).masked_fill(mask==1,float(0.0))\n",
        "  return mask\n",
        "\n",
        "def create_mask(src,tgt):\n",
        "  src_seq_len=src.shape[1]\n",
        "  tgt_seq_len=tgt.shape[1]\n",
        "\n",
        "  tgt_mask=generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask=torch.zeros((src_seq_len,src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask=(src==PAD_IDX)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "metadata": {
        "id": "wZSJKH0ETgPP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(NN.Module):\n",
        "  def __init__(self,d_model,dropout,max_len=5000):\n",
        "    super(PositionalEncoding,self).__init__()\n",
        "    self.dropout=NN.Dropout(p=dropout)\n",
        "\n",
        "    pe=torch.zeros(max_len,d_model)\n",
        "    position=torch.arange(0,max_len,dtype=torch.float).unsqueeze(1)\n",
        "    div_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000_0)/d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=x+self.pe[:,:x.size(1)]\n",
        "    return self.dropout(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "w8L7Fx-iUO6j"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(NN.Module):\n",
        "  def __init__(self,vocab_size:int,emb_size):\n",
        "    super(TokenEmbedding,self).__init__()\n",
        "    self.embedding=NN.Embedding(vocab_size,emb_size)\n",
        "    self.emb_size=emb_size\n",
        "\n",
        "  def forward(self,tokens:Tensor):\n",
        "    return self.embedding(tokens.long())*math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "lYqz7kCIWB6K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqTransformer(NN.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_encoder_layers:int,\n",
        "      num_decoder_layers:int,\n",
        "      emb_size:int,\n",
        "      nhead:int,\n",
        "      src_vocab_size:int,\n",
        "      tgt_vocab_size:int,\n",
        "      dim_feedforward:int=512,\n",
        "      dropout:float=0.1\n",
        "  ):\n",
        "    super(Seq2SeqTransformer,self).__init__()\n",
        "    self.transformer=Transformer(\n",
        "      d_model=emb_size,\n",
        "      nhead=nhead,\n",
        "      num_encoder_layers=num_encoder_layers,\n",
        "      num_decoder_layers=num_decoder_layers,\n",
        "      dim_feedforward=dim_feedforward,\n",
        "      dropout=dropout,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.generator = NN.Linear(emb_size, tgt_vocab_size)\n",
        "    self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "    self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "    self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      src:Tensor,\n",
        "      trg:Tensor,\n",
        "      src_mask:Tensor,\n",
        "      tgt_mask:Tensor,\n",
        "      src_padding_mask:Tensor,\n",
        "      tgt_padding_mask:Tensor,\n",
        "      memory_key_padding_mask:Tensor):\n",
        "\n",
        "    src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "    tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "    outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "    return self.generator(outs)\n",
        "  def encode(self, src: Tensor, src_mask: Tensor):\n",
        "    return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "  def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "    return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n"
      ],
      "metadata": {
        "id": "QNYlCjXUWuGI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2SeqTransformer(\n",
        "    NUM_ENCODER_LAYERS,\n",
        "    NUM_DECODER_LAYERS,\n",
        "    EMB_SIZE,\n",
        "    NHEAD,\n",
        "    SRC_VOCAB_SIZE,\n",
        "    TGT_VOCAB_SIZE,\n",
        "    FFN_HID_DIM\n",
        ").to(DEVICE)\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT07aREwYDy4",
        "outputId": "3f59a590-184f-4d8c-81f1-eaa32ac4395c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14,487,719 total parameters.\n",
            "14,487,719 training parameters.\n",
            "Seq2SeqTransformer(\n",
            "  (transformer): Transformer(\n",
            "    (encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-2): 3 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-2): 3 x TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=192, out_features=25319, bias=True)\n",
            "  (src_tok_emb): TokenEmbedding(\n",
            "    (embedding): Embedding(15389, 192)\n",
            "  )\n",
            "  (tgt_tok_emb): TokenEmbedding(\n",
            "    (embedding): Embedding(25319, 192)\n",
            "  )\n",
            "  (positional_encoding): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n"
      ],
      "metadata": {
        "id": "hE__l1n3YGBv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "def train_epoch(model, optimizer):\n",
        "    print('Training')\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    for src, tgt in tqdm(train_dataloader, total=len(list(train_dataloader))):\n",
        "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        logits = model(\n",
        "            src,\n",
        "            tgt_input,\n",
        "            src_mask,\n",
        "            tgt_mask,\n",
        "            src_padding_mask,\n",
        "            tgt_padding_mask,\n",
        "            src_padding_mask\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        tgt_out = tgt[:, 1:]\n",
        "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "    return losses / len(list(train_dataloader))"
      ],
      "metadata": {
        "id": "gXAhv3EnYV94"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYCPN06Td27o",
        "outputId": "b3f5daba-7858-4a69-f93b-7d665edff400"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "824"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "def evaluate(model):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    for src, tgt in tqdm(val_dataloader, total=len(list(val_dataloader))):\n",
        "        # print(\" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(src[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "        # print(\" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt[0].cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(\n",
        "            src,\n",
        "            tgt_input,\n",
        "            src_mask,\n",
        "            tgt_mask,\n",
        "            src_padding_mask,\n",
        "            tgt_padding_mask,\n",
        "            src_padding_mask\n",
        "        )\n",
        "        tgt_out = tgt[:, 1:]\n",
        "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
        "        losses += loss.item()\n",
        "    return losses / len(list(val_dataloader))"
      ],
      "metadata": {
        "id": "GgcGpo2oYgum"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVisGib_i3t7",
        "outputId": "e182bb6a-6458-4762-d774-9ee1e1afff48"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, valid_loss_list = [], []\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(model, optimizer)\n",
        "    valid_loss = evaluate(model)\n",
        "    end_time = timer()\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s \\n\"))"
      ],
      "metadata": {
        "id": "h5mvikCNYkwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('outputs', exist_ok=True)"
      ],
      "metadata": {
        "id": "WjOkOLSlYsHD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plots(train_loss, valid_loss):\n",
        "    \"\"\"\n",
        "    Function to save the loss plots to disk.\n",
        "    \"\"\"\n",
        "    # Loss plots.\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_loss, color='blue', linestyle='-',\n",
        "        label='train loss'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_loss, color='red', linestyle='-',\n",
        "        label='validataion loss'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join('outputs', 'loss.png'))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "307ppMx1Jhhm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_plots(train_loss_list, valid_loss_list)"
      ],
      "metadata": {
        "id": "2X87BLKYJkje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'outputs/model.pth')\n"
      ],
      "metadata": {
        "id": "p8hoDAHmJmKF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('outputs/model.pth')\n"
      ],
      "metadata": {
        "id": "ssJPftJSJrCP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1T36xZGlSNm",
        "outputId": "281c3967-2c27-48d1-ee82-8d0a59bc3c95"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2SeqTransformer(\n",
            "  (transformer): Transformer(\n",
            "    (encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-2): 3 x TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0-2): 3 x TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=192, out_features=25359, bias=True)\n",
            "  (src_tok_emb): TokenEmbedding(\n",
            "    (embedding): Embedding(15422, 192)\n",
            "  )\n",
            "  (tgt_tok_emb): TokenEmbedding(\n",
            "    (embedding): Embedding(25359, 192)\n",
            "  )\n",
            "  (positional_encoding): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to generate output sequence using greedy algorithm.\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        if i == 0:\n",
        "            ys = ys.transpose(1, 0)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "# Translation function.\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)\n",
        "    num_tokens = src.shape[1]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "metadata": {
        "id": "2u_4Y_syJvIK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SRC, GT pairs from the validation set.\n",
        "infer_sentences = [\n",
        "    [\"Take a seat.\", \"Prends place !\"],\n",
        "    [\"I'm not scared to die\", \"Je ne crains pas de mourir.\"],\n",
        "    [\"You'd better make sure that it is true.\", \"Tu ferais bien de t'assurer que c'est vrai.\"],\n",
        "    [\"The clock has stopped.\", \"L'horloge s'est arrêtée.\"],\n",
        "    [\"Take any two cards you like.\", \"Prends deux cartes de ton choix.\"]\n",
        "]\n",
        "for sentence in infer_sentences:\n",
        "    print(f\"SRC: {sentence[0]}\")\n",
        "    print(f\"GT: {sentence[1]}\")\n",
        "    print(f\"PRED: {translate(model, sentence[0])}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtdLRoluJ6VF",
        "outputId": "27320f9b-bb71-40cc-a084-ab6a1606633f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: Take a seat.\n",
            "GT: Prends place !\n",
            "PRED:  Arrête ! \n",
            "\n",
            "SRC: I'm not scared to die\n",
            "GT: Je ne crains pas de mourir.\n",
            "PRED:  Je ne suis pas à croire que je suis en suis pas\n",
            "\n",
            "SRC: You'd better make sure that it is true.\n",
            "GT: Tu ferais bien de t'assurer que c'est vrai.\n",
            "PRED:  Tu ferais mieux que ça est mieux . \n",
            "\n",
            "SRC: The clock has stopped.\n",
            "GT: L'horloge s'est arrêtée.\n",
            "PRED:  Le chat a été en train . \n",
            "\n",
            "SRC: Take any two cards you like.\n",
            "GT: Prends deux cartes de ton choix.\n",
            "PRED:  Les gens vous êtes deux deux . \n",
            "\n"
          ]
        }
      ]
    }
  ]
}